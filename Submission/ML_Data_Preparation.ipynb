{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing for ML models\n",
    "\n",
    "In this notebook, we process train_data.csv and test_data.csv before inputting it into our ML models. We also improve on the limitations of [this paper](https://ieeexplore.ieee.org/document/9084046). The authors of the paper did not share techniques to handle class imbalanced datasets. This could affect model accuracy if some target classes are underrepresented by the dataset. We did this using RandomOverSampler from the imblearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import contractions\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from numpy import *\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/Processed/train_data.csv')\n",
    "test_df = pd.read_csv('data/Processed/test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuation_pattern = re.compile(r'[^\\w\\s]')\n",
    "    clean_text = punctuation_pattern.sub('', text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Text'] = train_df['Text'].apply(lambda z: remove_punctuation(z))\n",
    "test_df['Text'] = test_df['Text'].apply(lambda z: remove_punctuation(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "train_df['Text'] = train_df['Text'].apply(tokenizer.tokenize)\n",
    "test_df['Text'] = test_df['Text'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'has', 'd', 'into', 'there', 'too', 'below', 'as', 'their', 'was', 'll', 'what', \"couldn't\", \"hadn't\", \"weren't\", 't', 'again', 'because', 'here', 'itself', 'herself', 'than', 'i', \"didn't\", 'but', 'our', \"isn't\", 'both', 'were', 'y', 'ain', 'under', 'most', 'to', \"she's\", 'where', 'those', 'all', 'wasn', \"wouldn't\", 'is', 'mightn', 'own', \"wasn't\", 'we', 'haven', 'did', 'm', 'can', \"you've\", 'being', 'from', \"hasn't\", 'am', \"mightn't\", 'ma', 'does', 'isn', \"shouldn't\", 'until', 'if', 'this', 'needn', 'have', 'few', 'couldn', 'and', 'for', 'wouldn', 'yourself', 'nor', 'didn', 'it', 'when', 'an', 'only', \"that'll\", \"should've\", 'any', \"you'd\", 'her', 'out', 'its', 'with', 'who', \"shan't\", 'himself', 'such', 'doing', 'won', 'whom', \"it's\", 'further', 'o', 'be', 'mustn', 'down', 'me', 'above', 'ourselves', 'once', \"you're\", 'during', 'through', 'shan', 'against', 'more', 'hasn', 'on', 'off', 'they', 'then', 'you', \"aren't\", 'a', 'the', 'your', 'doesn', \"won't\", 'should', \"don't\", 'my', 'of', 'him', 'aren', 'or', 'that', \"needn't\", 'how', 'while', 'before', 'having', 'up', 'shouldn', 'at', \"doesn't\", 'these', 'will', 'them', 'themselves', 'by', 'very', 'over', 'yourselves', 'other', 'some', 'just', \"mustn't\", 'been', 'yours', 'myself', 'ours', 'now', \"you'll\", 'do', 'each', 'no', 'which', 'hers', 's', 're', 'weren', 'about', 'not', 'hadn', 'had', 'same', 'his', 'in', 'she', 've', 'why', 'between', 'don', 'so', 'after', \"haven't\", 'are', 'theirs', 'he'}\n"
     ]
    }
   ],
   "source": [
    "# Just to check list of stopwords to ensure that the keep tokens isnt redunat\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    #Our n-grams analysis has shown that the <br> tag was not removed properly\n",
    "    stop_words.add('br')  \n",
    "\n",
    "    #Keep these words in the text as they could correlate to sentiment\n",
    "    keep_in_tokens = [\n",
    "        \"isn't\", \"is\",\n",
    "        \"wasn't\", \"was\",\n",
    "        \"aren't\", \"are\",\n",
    "        \"doesn't\", \"does\",\n",
    "        \"couldn't\", \"could\",\n",
    "        \"won't\", \"will\",\n",
    "        \"shouldn't\", \"should\",\n",
    "        \"didn't\", \"did\",\n",
    "        \"haven't\", \"have\"\n",
    "    ]\n",
    "    for word in keep_in_tokens:\n",
    "        stop_words.discard(word)  \n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Text'] = train_df['Text'].apply(filter_tokens)\n",
    "test_df['Text'] = test_df['Text'].apply(filter_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_tokens(filtered_tokens):\n",
    "  return ' '.join([lemmatizer.lemmatize(token) for token in filtered_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Text'] = train_df['Text'].apply(lemmatize_tokens)\n",
    "test_df['Text'] = test_df['Text'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep cleaned train Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saw premiered rewatched ifc is great telling m...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie is one alltime favorite think sean penn ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>describing stalingrad war film may bit inaccur...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tale two sister one creepiest film have seen r...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well notice imdb offered plot infothat is is p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>little picture succeeds many big picture fails...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>will love child saddest movie have ever seen d...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wow 3d imagery time wa used nicely provide goo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24 is best television show is incredible tv se...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wa moved film 1981 went back theater four time...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  saw premiered rewatched ifc is great telling m...          8\n",
       "1  movie is one alltime favorite think sean penn ...          6\n",
       "2  describing stalingrad war film may bit inaccur...          8\n",
       "3  tale two sister one creepiest film have seen r...          8\n",
       "4  well notice imdb offered plot infothat is is p...          1\n",
       "5  little picture succeeds many big picture fails...          7\n",
       "6  will love child saddest movie have ever seen d...          8\n",
       "7  wow 3d imagery time wa used nicely provide goo...          2\n",
       "8  24 is best television show is incredible tv se...          8\n",
       "9  wa moved film 1981 went back theater four time...          8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Deep cleaned train Dataset\")\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep cleaned test Dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frank horrigan clint eastwood is harassed mitc...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carly jones elisha curtberth bad boy brother n...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dig would say anyone even like metallica see k...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is great premise movie overall plot is origina...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>underground comedy movie is possibly worst tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>plot nutshell duchess voice eva gabor is well ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>liked film lot is dark is bulletdodging carcha...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>terrible movie represents perfectly state dege...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>know story group plucky nohopers enter competi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>boat builder sleepy town maine is going busine...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  frank horrigan clint eastwood is harassed mitc...          6\n",
       "1  carly jones elisha curtberth bad boy brother n...          5\n",
       "2  dig would say anyone even like metallica see k...          5\n",
       "3  is great premise movie overall plot is origina...          4\n",
       "4  underground comedy movie is possibly worst tra...          1\n",
       "5  plot nutshell duchess voice eva gabor is well ...          5\n",
       "6  liked film lot is dark is bulletdodging carcha...          7\n",
       "7  terrible movie represents perfectly state dege...          1\n",
       "8  know story group plucky nohopers enter competi...          5\n",
       "9  boat builder sleepy town maine is going busine...          5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Deep cleaned test Dataset\")\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data preparation notebook, we found that there was an imbalance of classes. We will now perform random oversampling on the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "1    7981\n",
       "8    7733\n",
       "6    4672\n",
       "4    4225\n",
       "3    3922\n",
       "5    3829\n",
       "7    3666\n",
       "2    3630\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "train_x, train_y = ros.fit_resample(np.array(train_df['Text']).reshape(-1, 1), np.array(train_df['Sentiment']).reshape(-1, 1))\n",
    "\n",
    "# Get Oversampled training data\n",
    "train_oversampled_df = pd.DataFrame(list(zip([x[0] for x in train_x], train_y)), columns = ['Text', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "8    7981\n",
       "6    7981\n",
       "1    7981\n",
       "7    7981\n",
       "2    7981\n",
       "4    7981\n",
       "3    7981\n",
       "5    7981\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oversampled_df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the train and test data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oversampled_df.to_csv(\"ML_train.csv\")\n",
    "test_df.to_csv(\"ML_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
